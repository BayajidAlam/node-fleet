# ğŸ¯ Technology Selection & Architecture Decisions

**Project**: SmartScale K3s Autoscaler  
**Date**: December 22, 2025  
**Status**: Planning & Design Phase

---

## ğŸ“‹ Requirements Analysis Summary

Based on Poridhi.io final exam requirements, we need:

1. âœ… Intelligent metric collection (Prometheus)
2. âœ… Smart scaling logic (Lambda-based)
3. âœ… Automated node provisioning (EC2 API)
4. âœ… Graceful deprovisioning (kubectl drain)
5. âœ… State management & race prevention (DynamoDB)
6. âœ… Monitoring & alerting (CloudWatch + Slack)
7. âœ… Security compliance (Secrets Manager, IAM)
8. âœ… Cost optimization (40-50% reduction)
9. âœ… Infrastructure as Code (Pulumi vs Terraform)

---

## ğŸ”§ Technology Stack Decisions

### 1. Infrastructure as Code (IaC)

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **Pulumi (Python)** | âœ… Same language as Lambda (Python)<br>âœ… Type safety & IDE autocomplete<br>âœ… Easier testing with pytest<br>âœ… Better for complex logic | âš ï¸ Smaller community<br>âš ï¸ Less enterprise adoption | **âœ… SELECTED** |
| **Terraform (HCL)** | âœ… Industry standard<br>âœ… Massive module library<br>âœ… Better state management | âŒ Different language from Lambda<br>âŒ HCL less expressive for logic | âŒ Rejected |

**Justification**: Python consistency across Lambda + Pulumi reduces context switching. Type safety catches errors before deployment. Team already knows Python.

---

### 2. Autoscaler Implementation

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **AWS Lambda** | âœ… Serverless (no servers to manage)<br>âœ… Pay per invocation (~$0.20/million)<br>âœ… Auto-scales itself<br>âœ… Easy EventBridge integration | âš ï¸ 15-minute max timeout<br>âš ï¸ Cold start latency | **âœ… SELECTED** |
| **ECS Fargate Container** | âœ… No timeout limit<br>âœ… Can run continuously | âŒ Always-on cost (~$15/month)<br>âŒ Need to manage container lifecycle | âŒ Rejected |
| **EC2 Instance** | âœ… Full control | âŒ High cost ($10-30/month)<br>âŒ Single point of failure<br>âŒ Need to manage OS | âŒ Rejected |
| **Kubernetes CronJob** | âœ… Native to K8s | âŒ Runs inside cluster being scaled<br>âŒ Circular dependency problem | âŒ Rejected |

**Justification**: Lambda is cost-effective ($3-5/month for 15,000 invocations), reliable, and aligns with serverless best practices. 60-second timeout sufficient for our scaling logic.

---

### 3. Metrics Collection

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **Prometheus** | âœ… K8s industry standard<br>âœ… Powerful PromQL queries<br>âœ… Pull-based (reliable)<br>âœ… Free & open source | âš ï¸ Need to expose endpoint<br>âš ï¸ Storage management | **âœ… SELECTED** |
| **CloudWatch Container Insights** | âœ… AWS-native<br>âœ… No installation | âŒ Limited K3s support<br>âŒ Expensive ($7-10/month)<br>âŒ Less flexible queries | âŒ Rejected |
| **Datadog** | âœ… Great UI<br>âœ… Advanced features | âŒ Very expensive ($15-31/host/month)<br>âŒ Overkill for project | âŒ Rejected |

**Justification**: Prometheus is free, K8s-native, and provides exactly the metrics we need. PromQL is powerful for custom scaling logic.

**Exposure Strategy**: NodePort (port 30090) + Security Group restricting Lambda's VPC only. No public internet access. No auth needed (network-level security).

---

### 4. State Management & Locking

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **DynamoDB** | âœ… Conditional writes (atomic locking)<br>âœ… Serverless (auto-scales)<br>âœ… Fast (<10ms latency)<br>âœ… Pay per request | âš ï¸ Need to design schema carefully | **âœ… SELECTED** |
| **S3 + Object Lock** | âœ… Simple | âŒ Eventual consistency issues<br>âŒ No atomic operations<br>âŒ Slower | âŒ Rejected |
| **ElastiCache Redis** | âœ… Very fast<br>âœ… Native locking | âŒ Always-on cost ($15-50/month)<br>âŒ Overkill for our needs | âŒ Rejected |

**Justification**: DynamoDB's conditional writes (`ConditionExpression`) provide atomic distributed locking. Pay-per-request pricing is cost-effective for our infrequent writes (1 write/2 minutes).

**Schema Design**:
```python
{
  "cluster_id": "k3s-techflow-prod",  # Partition key
  "node_count": 5,
  "last_scale_time": "2025-12-22T10:30:00Z",
  "last_scale_action": "scale_up",
  "scaling_in_progress": false,
  "lock_holder": null,
  "lock_expiry": null,
  "last_cpu_avg": 72.5,
  "last_memory_avg": 68.2,
  "last_pending_pods": 3
}
```

---

### 5. Secret Management

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **AWS Secrets Manager** | âœ… Automatic rotation support<br>âœ… Encryption at rest<br>âœ… Versioning<br>âœ… Audit logs | âš ï¸ $0.40/secret/month | **âœ… SELECTED** |
| **AWS Systems Manager Parameter Store** | âœ… Free for standard params<br>âœ… Simple API | âŒ No automatic rotation<br>âŒ Limited features | âš ï¸ Acceptable alternative |
| **S3 with encryption** | âœ… Cheap | âŒ Not designed for secrets<br>âŒ No rotation<br>âŒ Manual key management | âŒ Rejected |

**Justification**: Secrets Manager is purpose-built for secrets. K3s join token is critical - worth $0.40/month for proper security, rotation, and audit trail.

**Stored Secrets**:
- `k3s/join-token` - K3s cluster join token
- `k3s/master-ip` - Master node private IP (if using static IP)

---

### 6. Monitoring & Alerting

| Component | Technology | Justification |
|-----------|-----------|---------------|
| **Cluster Metrics** | Prometheus + node_exporter | K8s standard, already decided |
| **Lambda Logs** | CloudWatch Logs | AWS-native, automatic |
| **Custom Metrics** | CloudWatch Metrics (boto3) | Track scaling events, node count |
| **Dashboards** | CloudWatch Dashboards | Free, AWS-native, sufficient for MVP |
| **Advanced Dashboards** | Grafana (optional) | Better visualization, but requires hosting |
| **Alerts** | CloudWatch Alarms + SNS | Free tier: 10 alarms, simple setup |
| **Notifications** | Slack Webhooks (via SNS) | Better UX than email, real-time visibility |

**CloudWatch Metrics to Create**:
- `AutoscalerInvocations` (count)
- `ScaleUpEvents` (count, dimension: reason)
- `ScaleDownEvents` (count)
- `ScalingFailures` (count, dimension: error_type)
- `CurrentNodeCount` (gauge)
- `NodeJoinLatency` (milliseconds)
- `LambdaExecutionTime` (milliseconds)

**CloudWatch Alarms**:
1. `ScalingFailure` - 3 failures in 15 minutes â†’ SNS â†’ Slack
2. `ClusterCPUCritical` - CPU > 90% for 5 minutes â†’ urgent alert
3. `MaxCapacityReached` - node_count = 10 for 10 minutes â†’ warning
4. `NodeJoinFailure` - join latency > 5 minutes â†’ alert

---

### 7. Container Orchestration

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **K3s** | âœ… Lightweight (40 MB vs 400 MB)<br>âœ… Single binary<br>âœ… Perfect for small clusters<br>âœ… Built-in components | âš ï¸ Less production adoption | **âœ… SELECTED** |
| **K8s (kubeadm)** | âœ… Industry standard | âŒ Complex setup<br>âŒ Resource-heavy<br>âŒ Overkill for project | âŒ Rejected |
| **EKS** | âœ… Managed | âŒ $73/month just for control plane<br>âŒ Defeats purpose of cost optimization | âŒ Rejected |

**Justification**: Requirements explicitly specify K3s. Perfect for lightweight, cost-effective Kubernetes.

---

### 8. Load Testing

| Tool | Pros | Cons | Decision |
|------|------|------|----------|
| **k6** | âœ… Modern, JS-based<br>âœ… Great reporting<br>âœ… Cloud integration option | âš ï¸ Need to learn JS | **âœ… SELECTED** |
| **Locust** | âœ… Python-based<br>âœ… Distributed load | âš ï¸ UI can be unstable | âš ï¸ Backup option |
| **Apache Bench** | âœ… Simple | âŒ Limited features<br>âŒ No scripting | âŒ Too basic |

**Justification**: k6 is modern, has excellent reporting, and can simulate realistic user patterns. Python alternative (Locust) available if needed.

---

### 9. CI/CD & GitOps (Optional Bonus)

| Option | Pros | Cons | Decision |
|--------|------|------|----------|
| **FluxCD** | âœ… Lightweight<br>âœ… GitOps native | âš ï¸ Newer project | âš ï¸ Bonus feature |
| **ArgoCD** | âœ… Great UI<br>âœ… Mature | âš ï¸ More resource-heavy | âš ï¸ Bonus feature |
| **Manual deployment** | âœ… Simple for MVP | âŒ Not production-ready | **âœ… Phase 1 approach** |

**Justification**: Focus on core autoscaling first. Add GitOps in Phase 4 if time permits.

---

### 10. Cost Optimization Strategies

| Strategy | Technology | Cost Impact | Priority |
|----------|-----------|-------------|----------|
| **Dynamic scaling** | Lambda + EC2 API | **-50% infra cost** | âœ… Core |
| **Spot instances** | EC2 Spot + interruption handling | **-60-70% instance cost** | âš ï¸ Bonus (Phase 4) |
| **Multi-AZ balancing** | Custom logic in Lambda | Resilience, not cost | âš ï¸ Bonus (Phase 4) |
| **Predictive scaling** | Historical data analysis | **-10-15% additional** | âš ï¸ Bonus (Phase 4) |
| **Right-sizing instances** | t3.small â†’ t3.micro for off-peak | **-20% per node** | âœ… Phase 2 |

**Cost Analysis** (monthly, Bangladesh pricing):
- **Before**: 5 Ã— t3.small Ã— 24/7 = ~1.2 lakh BDT
- **After** (dynamic scaling):
  - Off-peak (12h): 2 Ã— t3.small = ~24,000 BDT
  - Peak (12h): 7 Ã— t3.small = ~42,000 BDT
  - Lambda: ~300 BDT
  - DynamoDB: ~100 BDT
  - **Total**: ~66,400 BDT (**45% savings** = ~53,600 BDT/month)

---

## ğŸ—ï¸ Architecture Components Map

```
Component               Technology          Why This Choice
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IaC                    Pulumi (Python)     Same language as Lambda
Autoscaler             AWS Lambda          Serverless, cost-effective
Trigger                EventBridge         2-minute interval, reliable
Metrics                Prometheus          K8s standard, powerful PromQL
State/Locking          DynamoDB            Atomic conditional writes
Secrets                Secrets Manager     Secure, auditable, rotation
Cluster                K3s                 Lightweight Kubernetes
Nodes                  EC2 t3.small        Balanced CPU/memory/cost
Monitoring             CloudWatch          AWS-native, free tier
Alerting               CloudWatch Alarms   Simple, integrated with SNS
Notifications          SNS â†’ Slack         Real-time team visibility
Load Testing           k6                  Modern, JS-based, great reports
Dashboards             CloudWatch          Free, sufficient for MVP
Optional: Advanced UI  Grafana             Better viz (Phase 3/4)
Optional: GitOps       FluxCD              Config versioning (Phase 4)
```

---

## ğŸ”’ Security Architecture

| Requirement | Implementation | Technology |
|-------------|----------------|------------|
| **No hardcoded credentials** | IAM roles everywhere | AWS IAM |
| **K3s token security** | Encrypted storage | Secrets Manager |
| **Lambda permissions** | Least-privilege policy | IAM Policy (JSON) |
| **Prometheus access** | Security group + NodePort | AWS VPC |
| **EC2 volume encryption** | EBS encryption at rest | AWS KMS |
| **Inter-node comms** | K3s built-in TLS | K3s default |
| **Audit logging** | All API calls logged | CloudTrail |

---

## ğŸ“Š Component Interaction Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: Trigger (Every 2 minutes)                          â”‚
â”‚  EventBridge Rule â†’ Lambda Invocation                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: Lock Check (Race condition prevention)             â”‚
â”‚  Lambda â†’ DynamoDB.get_item(cluster_id)                     â”‚
â”‚  Check: scaling_in_progress == false                        â”‚
â”‚  IF locked: exit gracefully, retry next invocation          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: Metrics Collection                                 â”‚
â”‚  Lambda â†’ Prometheus HTTP API (NodePort 30090)              â”‚
â”‚  Query: avg CPU, avg Memory, pending pods, current nodes    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: Scaling Decision                                   â”‚
â”‚  Python logic evaluates:                                    â”‚
â”‚  - Scale UP if: CPU>70% OR pending_pods>0 OR memory>75%     â”‚
â”‚  - Scale DOWN if: CPU<30% AND pending_pods=0 AND memory<50% â”‚
â”‚  - NO ACTION if: within normal range or cooldown active     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5a: Scale UP (if needed)                              â”‚
â”‚  Lambda â†’ DynamoDB.put_item(scaling_in_progress=true)       â”‚
â”‚  Lambda â†’ Secrets Manager.get_secret(k3s-token)             â”‚
â”‚  Lambda â†’ EC2.run_instances(user_data=worker-script)        â”‚
â”‚  Wait for instance "running"                                â”‚
â”‚  Poll kubectl: wait for node "Ready" (max 5 min)            â”‚
â”‚  Lambda â†’ DynamoDB.update(node_count++, lock=false)         â”‚
â”‚  Lambda â†’ SNS.publish("Scale-up: +2 nodes, CPU was 78%")    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5b: Scale DOWN (if needed)                            â”‚
â”‚  Lambda â†’ DynamoDB.put_item(scaling_in_progress=true)       â”‚
â”‚  Identify least-utilized node (fewest pods)                 â”‚
â”‚  Lambda â†’ kubectl cordon <node>                             â”‚
â”‚  Lambda â†’ kubectl drain <node> --timeout=5m                 â”‚
â”‚  Wait for drain completion                                  â”‚
â”‚  Lambda â†’ EC2.terminate_instances(instance_id)              â”‚
â”‚  Lambda â†’ DynamoDB.update(node_count--, lock=false)         â”‚
â”‚  Lambda â†’ SNS.publish("Scale-down: -1 node, CPU was 25%")   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 6: Logging & Metrics                                  â”‚
â”‚  Lambda â†’ CloudWatch Logs (decision rationale)              â”‚
â”‚  Lambda â†’ CloudWatch Metrics (custom metrics)               â”‚
â”‚  SNS â†’ Slack Webhook (team notification)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Technology Selection Summary

**Selected Stack**:
- â˜ï¸ **Cloud**: AWS (EC2, Lambda, DynamoDB, Secrets Manager, CloudWatch)
- ğŸ—ï¸ **IaC**: Pulumi (Python)
- ğŸ¤– **Autoscaler**: AWS Lambda (Python 3.11, EventBridge trigger)
- ğŸ“Š **Metrics**: Prometheus (NodePort exposure)
- ğŸ—„ï¸ **State**: DynamoDB (conditional writes)
- ğŸ” **Secrets**: AWS Secrets Manager
- â˜¸ï¸ **Cluster**: K3s (lightweight Kubernetes)
- ğŸ’» **Nodes**: EC2 t3.small (Ubuntu 22.04 LTS)
- ğŸ“ˆ **Monitoring**: CloudWatch + Grafana (optional)
- ğŸ”” **Alerts**: CloudWatch Alarms + SNS + Slack
- ğŸ§ª **Load Testing**: k6

**Why This Stack Wins**:
1. âœ… Meets all Poridhi.io requirements (100% coverage)
2. âœ… Cost-effective (45-50% infrastructure savings)
3. âœ… Python throughout (Lambda + Pulumi + testing)
4. âœ… Serverless where possible (Lambda > always-on)
5. âœ… AWS-native services (easier integration)
6. âœ… Production-ready security (Secrets Manager, IAM roles)
7. âœ… Scalable architecture (no bottlenecks)
8. âœ… Well-documented ecosystem (Prometheus, K3s, boto3)

---

## ğŸ“ Learning & Skill Development

This stack teaches:
- âœ… Serverless architectures (Lambda)
- âœ… Infrastructure as Code (Pulumi)
- âœ… Kubernetes fundamentals (K3s)
- âœ… Metrics & observability (Prometheus, CloudWatch)
- âœ… Distributed systems (locking, race conditions)
- âœ… AWS services (10+ services integrated)
- âœ… Python best practices (boto3, error handling)
- âœ… Security engineering (IAM, Secrets Manager)

---

## ğŸ“ Next Step: Implementation Phases

See [IMPLEMENTATION_PHASES.md](./IMPLEMENTATION_PHASES.md) for detailed 4-phase rollout plan.
